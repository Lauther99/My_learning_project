{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\lauth\\\\OneDrive\\\\Desktop\\\\hola\\\\My_learning_project\\\\open_source_models_with_huggingface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lauth\\OneDrive\\Desktop\\hola\\My_learning_project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "c:\\Users\\lauth\\OneDrive\\Desktop\\hola\\My_learning_project\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from datasets import Audio\n",
    "\n",
    "dataset = load_dataset(\"ashraq/esc50\", split=\"train[0:100]\")\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=48_000))\n",
    "audio_classifier = pipeline(task=\"zero-shot-audio-classification\", model=\"laion/clap-htsat-unfused\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9929959177970886, 'label': 'Sound of can'}, {'score': 0.0068225739523768425, 'label': 'Sound of vaccum cleaner'}, {'score': 0.0001602840784471482, 'label': 'Sound of a dog'}, {'score': 2.1278150597936474e-05, 'label': 'Sound of birds'}]\n"
     ]
    }
   ],
   "source": [
    "audio = dataset[7][\"audio\"][\"array\"]\n",
    "candidate_labels = [\n",
    "    \"Sound of a dog\",\n",
    "    \"Sound of birds\",\n",
    "    \"Sound of vaccum cleaner\",\n",
    "    \"Sound of can\",\n",
    "]\n",
    "\n",
    "output = audio_classifier(\n",
    "    audio,\n",
    "    candidate_labels=candidate_labels,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.02796525e-05,  1.87270825e-06, -4.22278163e-06, ...,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[9][\"audio\"][\"array\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando...\n",
      "Grabación completada.\n",
      "Archivo WAV 'grabacion.wav' guardado.\n",
      "Frecuencia de muestreo: 48000 Hz\n",
      "Primeras 10 muestras de amplitud: [ 0.0000000e+00  0.0000000e+00 -3.0517578e-05  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00 -3.0517578e-05\n",
      "  0.0000000e+00  0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write, read\n",
    "import numpy as np\n",
    "\n",
    "# Definir la frecuencia de muestreo y duración de la grabación\n",
    "sample_rate = 48000  # Frecuencia de muestreo (48kHz para compatibilidad con el dataset)\n",
    "duration = 5  # Duración en segundos\n",
    "\n",
    "# Grabar el sonido\n",
    "print(\"Grabando...\")\n",
    "audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')\n",
    "sd.wait()  # Esperar a que la grabación termine\n",
    "print(\"Grabación completada.\")\n",
    "\n",
    "# Guardar el sonido grabado como un archivo WAV\n",
    "write('grabacion.wav', sample_rate, audio_data)\n",
    "print(\"Archivo WAV 'grabacion.wav' guardado.\")\n",
    "\n",
    "# Leer el archivo WAV para obtener el array de amplitudes y la frecuencia de muestreo\n",
    "sampling_rate, data = read('grabacion.wav')\n",
    "\n",
    "# Ver los primeros 10 valores del array de amplitud\n",
    "print(f\"Frecuencia de muestreo: {sampling_rate} Hz\")\n",
    "print(f\"Primeras 10 muestras de amplitud: {data[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0000000e+00,  0.0000000e+00, -3.0517578e-05, ...,\n",
       "       -3.0517578e-05, -3.0517578e-05, -6.1035156e-05], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.8787619471549988, 'label': 'Person talking'}, {'score': 0.11977901309728622, 'label': 'Person talking in spanish'}, {'score': 0.0009302571997977793, 'label': 'Sound of birds'}, {'score': 0.00039031822234392166, 'label': 'Sound of a dog'}, {'score': 0.00013846979709342122, 'label': 'Sound of vaccum cleaner'}]\n"
     ]
    }
   ],
   "source": [
    "candidate_labels = [\n",
    "    \"Sound of a dog\",\n",
    "    \"Sound of birds\",\n",
    "    \"Sound of vaccum cleaner\",\n",
    "    \"Person talking in english\",\n",
    "    \"Person talking in spanish\",\n",
    "]\n",
    "\n",
    "output = audio_classifier(\n",
    "    data,\n",
    "    candidate_labels=candidate_labels,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencia de muestreo: 44100\n",
      "Primeras 10 muestras de amplitud: [ 0.0000000e+00  3.4650850e-12  1.2282744e-11 -3.3963873e-12\n",
      "  1.7464138e-11  1.4789694e-11 -9.3588141e-12 -4.1115496e-12\n",
      " -6.0302950e-11 -5.4613102e-12]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "# Cargar el archivo de audio MP3\n",
    "audio_path = '006.mp3'\n",
    "audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
    "\n",
    "# Mostrar información del archivo\n",
    "print(f\"Frecuencia de muestreo: {sample_rate}\")\n",
    "print(f\"Primeras 10 muestras de amplitud: {audio_data[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.7824869155883789, 'label': 'Person talking in portuguese'}, {'score': 0.2175130993127823, 'label': 'Person talking in english'}]\n"
     ]
    }
   ],
   "source": [
    "candidate_labels = [\n",
    "    \"Person talking in english\",\n",
    "    \"Person talking in portuguese\",\n",
    "]\n",
    "\n",
    "# Mientras menos opciones, mayor probabilidad de que responda bien\n",
    "\n",
    "output = audio_classifier(\n",
    "    audio_data,\n",
    "    candidate_labels=candidate_labels,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
